>>> spark_df.write.mode("overwrite").saveAsTable('name')
>>> spark.sql("select * from name").show()                                      
+-------+------+---+----------+--------+
|user_id|gender|age|occupation|zip_code|
+-------+------+---+----------+--------+
|   5923|     M| 25|         7|    5401|
|   5924|     M| 35|         0|   55417|
|   5925|     F| 25|         0|    null|
|   5926|     F| 50|         7|   65712|
|   5927|     M| 35|        14|   10003|
|   5928|     M| 45|         1|   14760|
|   5929|     F| 35|         0|   33607|
|   5930|     F| 35|        17|   78681|
|   5931|     F| 18|         7|   94111|
|   5932|     M| 18|        14|   90038|
|   5933|     M| 25|         2|   98227|
|   5934|     M| 25|        14|   77075|
|   5935|     M| 18|         0|   35115|
|   5936|     M| 18|         4|   37130|
|   5937|     M| 25|        12|   60622|
|   5938|     M| 25|         1|   35401|
|   5939|     F| 45|        15|   77040|
|   5940|     M| 50|        12|    3062|
|   5941|     F| 25|         0|   60640|
|   5942|     M| 45|         1|    1867|
+-------+------+---+----------+--------+
only showing top 20 rows

>>> spark.sql("show tables").show()
23/05/27 12:39:00 WARN ObjectStore: Failed to get database global_temp, returning NoSuchObjectException
+---------+-----------+-----------+
|namespace|  tableName|isTemporary|
+---------+-----------+-----------+
|  default|       name|      false|
